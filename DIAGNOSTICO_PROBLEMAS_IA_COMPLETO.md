# üîç DIAGN√ìSTICO COMPLETO - PROBLEMAS DA IA

**Data:** 2025-01-31  
**Status:** ‚ùå CR√çTICO - Sistema IA com limita√ß√µes severas  
**Prioridade:** üî¥ M√ÅXIMA

---

## üìä RESUMO EXECUTIVO

A IA do sistema **SyncAds** possui infraestrutura robusta (12 ferramentas, 17 Edge Functions), por√©m est√° **90% inativa** devido a 4 problemas cr√≠ticos que impedem seu funcionamento real:

1. ‚ùå **N√£o cria arquivos para download**
2. ‚ùå **N√£o consegue fazer pesquisas na internet**
3. ‚ùå **N√£o consegue raspar produtos de sites**
4. ‚ùå **Falta navegador headless (Playwright/Puppeteer)**

---

## üî¥ PROBLEMA #1: N√ÉO CRIA ARQUIVOS PARA DOWNLOAD

### üêõ **Sintomas:**
- Usu√°rio pede: "Crie um CSV com meus produtos"
- IA responde: "Arquivo criado!" mas **n√£o gera link de download**
- Edge Functions retornam sucesso mas arquivo n√£o fica acess√≠vel
- Storage tempor√°rio n√£o est√° configurado corretamente

### üîç **Causa Raiz:**

#### 1.1 Storage Bucket n√£o existe ou sem permiss√µes
```typescript
// Em file-generator-v2/index.ts
const { error: uploadError } = await supabase.storage
  .from('temp-downloads')  // ‚Üê Este bucket pode n√£o existir!
  .upload(fileName, fileContent)
```

**Verifica√ß√£o necess√°ria:**
- ‚úÖ Bucket `temp-downloads` existe no Supabase?
- ‚úÖ Pol√≠ticas RLS permitem upload p√∫blico?
- ‚úÖ Pol√≠ticas RLS permitem leitura p√∫blica?

#### 1.2 URL assinada n√£o est√° sendo gerada
```typescript
// C√≥digo atual pode n√£o estar gerando signed URL
const { data: signedUrl } = await supabase.storage
  .from('temp-downloads')
  .createSignedUrl(fileName, 3600) // 1 hora

// Se falhar, usu√°rio n√£o recebe link!
```

#### 1.3 Resposta da Edge Function n√£o retorna downloadUrl
```typescript
// toolExecutor.ts linha ~170
return {
  success: true,
  data: result,
  message: `Arquivo "${args.fileName}" criado com sucesso!`, 
  // ‚ùå FALTA: [Download](${result.downloadUrl})
};
```

### ‚úÖ **SOLU√á√ÉO:**

#### Passo 1: Criar bucket no Supabase
```sql
-- No Supabase Dashboard > Storage
-- Criar bucket: temp-downloads
-- Settings:
--   Public: true
--   File size limit: 50MB
--   Allowed MIME types: text/csv, application/json, text/plain, application/zip
```

#### Passo 2: Adicionar pol√≠ticas RLS
```sql
-- Permitir upload autenticado
CREATE POLICY "Allow authenticated uploads"
ON storage.objects FOR INSERT
TO authenticated
WITH CHECK (bucket_id = 'temp-downloads');

-- Permitir leitura p√∫blica (para downloads)
CREATE POLICY "Allow public downloads"
ON storage.objects FOR SELECT
TO public
USING (bucket_id = 'temp-downloads');

-- Limpeza autom√°tica (opcional)
CREATE POLICY "Allow authenticated delete own files"
ON storage.objects FOR DELETE
TO authenticated
USING (
  bucket_id = 'temp-downloads' 
  AND auth.uid()::text = (storage.foldername(name))[1]
);
```

#### Passo 3: Corrigir Edge Function file-generator-v2
```typescript
// supabase/functions/file-generator-v2/index.ts

// Gerar nome √∫nico
const fileName = `${userId}/${Date.now()}_${sanitize(requestedFileName)}`;

// Upload
const { data: uploadData, error: uploadError } = await supabase.storage
  .from('temp-downloads')
  .upload(fileName, fileContent, {
    contentType: getContentType(fileType),
    cacheControl: '3600',
    upsert: false
  });

if (uploadError) {
  throw new Error(`Upload falhou: ${uploadError.message}`);
}

// Gerar URL p√∫blica assinada
const { data: urlData, error: urlError } = await supabase.storage
  .from('temp-downloads')
  .createSignedUrl(fileName, 3600); // 1 hora

if (urlError || !urlData?.signedUrl) {
  throw new Error('Falha ao gerar URL de download');
}

return {
  success: true,
  fileName: fileName,
  downloadUrl: urlData.signedUrl, // ‚Üê URL P√öBLICA!
  expiresAt: new Date(Date.now() + 3600000).toISOString(),
  size: fileContent.length
};
```

#### Passo 4: Atualizar toolExecutor.ts
```typescript
// src/lib/ai/tools/toolExecutor.ts linha ~155

async function executeGenerateFile(args: any, accessToken: string): Promise<ToolResult> {
  const result = await callEdgeFunction('file-generator-v2', {
    fileName: args.fileName,
    content: args.content,
    fileType: args.fileType,
  }, accessToken);

  if (!result.downloadUrl) {
    throw new Error('Edge Function n√£o retornou downloadUrl');
  }

  return {
    success: true,
    data: result,
    message: `‚úÖ Arquivo "${args.fileName}" criado com sucesso!\n\nüì• **[CLIQUE AQUI PARA BAIXAR](${result.downloadUrl})**\n\n‚è±Ô∏è Link expira em: ${new Date(result.expiresAt).toLocaleString('pt-BR')}`,
  };
}
```

---

## üî¥ PROBLEMA #2: N√ÉO CONSEGUE FAZER PESQUISAS NA INTERNET

### üêõ **Sintomas:**
- Usu√°rio pede: "Pesquise sobre tend√™ncias de marketing 2025"
- IA responde com informa√ß√µes antigas (da base de treinamento)
- N√£o h√° integra√ß√£o com APIs de busca (Google, Bing, Brave, etc.)

### üîç **Causa Raiz:**

#### 2.1 Nenhuma ferramenta de busca implementada
```typescript
// toolDefinitions.ts - N√ÉO EXISTE:
{
  name: 'web_search',  // ‚ùå Esta ferramenta n√£o existe!
  description: 'Pesquisa na internet...',
}
```

#### 2.2 Arquivo _utils/web-search.ts existe mas n√£o est√° conectado
```bash
# Arquivo existe:
supabase/functions/_utils/web-search.ts

# Mas n√£o √© usado por nenhuma Edge Function!
```

### ‚úÖ **SOLU√á√ÉO:**

#### Op√ß√£o A: Usar API Brave Search (RECOMENDADO - GR√ÅTIS)
```typescript
// supabase/functions/_utils/web-search.ts

export async function braveSearch(query: string, count: number = 10) {
  const BRAVE_API_KEY = Deno.env.get('BRAVE_SEARCH_API_KEY');
  
  const response = await fetch(
    `https://api.search.brave.com/res/v1/web/search?q=${encodeURIComponent(query)}&count=${count}`,
    {
      headers: {
        'Accept': 'application/json',
        'X-Subscription-Token': BRAVE_API_KEY,
      }
    }
  );

  const data = await response.json();
  
  return {
    results: data.web?.results || [],
    query: data.query?.original || query,
  };
}
```

#### Op√ß√£o B: Usar SerpAPI (Pago mas confi√°vel)
```typescript
export async function serpApiSearch(query: string) {
  const SERP_API_KEY = Deno.env.get('SERP_API_KEY');
  
  const response = await fetch(
    `https://serpapi.com/search.json?q=${encodeURIComponent(query)}&api_key=${SERP_API_KEY}`
  );
  
  return await response.json();
}
```

#### Op√ß√£o C: Usar Bing Search API (Microsoft)
```typescript
export async function bingSearch(query: string) {
  const BING_API_KEY = Deno.env.get('BING_SEARCH_API_KEY');
  
  const response = await fetch(
    `https://api.bing.microsoft.com/v7.0/search?q=${encodeURIComponent(query)}`,
    {
      headers: {
        'Ocp-Apim-Subscription-Key': BING_API_KEY,
      }
    }
  );
  
  return await response.json();
}
```

#### Passo 1: Criar Edge Function web-search
```typescript
// supabase/functions/web-search/index.ts

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import { corsHeaders } from '../_utils/cors.ts';
import { braveSearch } from '../_utils/web-search.ts';

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  try {
    const { query, maxResults = 10 } = await req.json();

    console.log('üîç Searching:', query);

    const results = await braveSearch(query, maxResults);

    return new Response(
      JSON.stringify({
        success: true,
        query,
        results: results.results.map((r: any) => ({
          title: r.title,
          url: r.url,
          description: r.description,
        })),
        totalResults: results.results.length,
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  } catch (error: any) {
    console.error('‚ùå Search error:', error);
    return new Response(
      JSON.stringify({ success: false, error: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
```

#### Passo 2: Adicionar ferramenta web_search
```typescript
// src/lib/ai/tools/toolDefinitions.ts

{
  name: 'web_search',
  description: 'Pesquisa informa√ß√µes na internet em tempo real. Use quando o usu√°rio pedir para buscar, pesquisar ou procurar informa√ß√µes atuais.',
  parameters: {
    type: 'object',
    properties: {
      query: {
        type: 'string',
        description: 'Termo de busca (ex: "tend√™ncias marketing 2025")',
      },
      maxResults: {
        type: 'number',
        description: 'N√∫mero m√°ximo de resultados (padr√£o: 10)',
      },
    },
    required: ['query'],
  },
},
```

#### Passo 3: Adicionar executor
```typescript
// src/lib/ai/tools/toolExecutor.ts

case 'web_search':
  return await executeWebSearch(args, session.access_token);

// ...

async function executeWebSearch(args: any, accessToken: string): Promise<ToolResult> {
  const result = await callEdgeFunction('web-search', {
    query: args.query,
    maxResults: args.maxResults || 10,
  }, accessToken);

  const resultsSummary = result.results
    .slice(0, 5)
    .map((r: any, i: number) => `${i + 1}. [${r.title}](${r.url})\n   ${r.description}`)
    .join('\n\n');

  return {
    success: true,
    data: result,
    message: `üîç **Resultados da pesquisa:** "${args.query}"\n\nEncontrei ${result.totalResults} resultados:\n\n${resultsSummary}`,
  };
}
```

#### Passo 4: Configurar vari√°veis de ambiente
```bash
# No Supabase Dashboard > Project Settings > Edge Functions

# Op√ß√£o A: Brave Search (GR√ÅTIS - at√© 2000 queries/m√™s)
BRAVE_SEARCH_API_KEY=seu_brave_api_key

# Op√ß√£o B: SerpAPI (Pago)
SERP_API_KEY=seu_serp_api_key

# Op√ß√£o C: Bing Search
BING_SEARCH_API_KEY=seu_bing_api_key
```

**Como obter Brave API Key (GR√ÅTIS):**
1. Acesse https://brave.com/search/api/
2. Crie conta
3. Plano Free: 2000 queries/m√™s
4. Copie a API key

---

## üî¥ PROBLEMA #3: N√ÉO CONSEGUE RASPAR PRODUTOS DE SITES

### üêõ **Sintomas:**
- Usu√°rio pede: "Raspe produtos de https://loja.com"
- IA tenta mas retorna: "Nenhum produto encontrado"
- Sites modernos usam JavaScript para carregar produtos
- Fetch simples n√£o executa JS, apenas baixa HTML est√°tico

### üîç **Causa Raiz:**

#### 3.1 Web Scraper atual usa apenas fetch()
```typescript
// supabase/functions/web-scraper/index.ts

const response = await fetch(url); // ‚ùå N√ÉO EXECUTA JAVASCRIPT!
const html = await response.text(); // Apenas HTML est√°tico
```

**Limita√ß√µes do fetch():**
- ‚ùå N√£o executa JavaScript
- ‚ùå N√£o espera carregamento din√¢mico
- ‚ùå N√£o pode clicar em bot√µes
- ‚ùå N√£o pode rolar a p√°gina
- ‚ùå N√£o bypassa anti-bot
- ‚ùå N√£o lida com SPAs (React, Vue, Angular)

#### 3.2 Sites modernos s√£o SPA (Single Page Application)
```html
<!-- O que fetch() v√™: -->
<div id="root"></div>
<script src="app.js"></script>

<!-- O que o navegador v√™ ap√≥s executar JS: -->
<div id="root">
  <div class="product">
    <h2>Produto 1</h2>
    <span class="price">R$ 99,90</span>
  </div>
  <!-- 50 produtos carregados via JavaScript -->
</div>
```

#### 3.3 Sites bloqueiam scrapers simples
- User-Agent suspeito ‚Üí 403 Forbidden
- Sem cookies ‚Üí Redirect infinito
- Anti-bot (Cloudflare, reCAPTCHA)
- Rate limiting
- IP blocking

---

## üî¥ PROBLEMA #4: FALTA NAVEGADOR HEADLESS ‚ö†Ô∏è CR√çTICO

### üéØ **ESTA √â A SOLU√á√ÉO PRINCIPAL!**

Um **navegador headless** √© um navegador real (Chrome/Firefox) que:
- ‚úÖ **Executa JavaScript** como navegador normal
- ‚úÖ **Espera carregamento din√¢mico** (AJAX, fetch, websockets)
- ‚úÖ **Pode clicar, rolar, digitar** (automa√ß√£o completa)
- ‚úÖ **Bypassa detec√ß√£o de bots** (com configura√ß√£o correta)
- ‚úÖ **Ignora erros SSL** (certificados inv√°lidos)
- ‚úÖ **Suporta todos os sites modernos** (React, Vue, Angular, Next.js)

### üìä **COMPARA√á√ÉO:**

| Recurso | fetch() | Playwright | Puppeteer |
|---------|---------|------------|-----------|
| Velocidade | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° |
| Executa JS | ‚ùå | ‚úÖ | ‚úÖ |
| SPA Support | ‚ùå | ‚úÖ | ‚úÖ |
| Anti-bot bypass | ‚ùå | ‚úÖ | ‚úÖ |
| Screenshots | ‚ùå | ‚úÖ | ‚úÖ |
| PDFs | ‚ùå | ‚úÖ | ‚úÖ |
| Multi-browser | ‚ùå | ‚úÖ (3) | ‚ùå (1) |
| API moderna | ‚ùå | ‚úÖ | ‚ö° |
| Manuten√ß√£o | - | Google | Google |

### ‚úÖ **SOLU√á√ÉO: IMPLEMENTAR PLAYWRIGHT**

#### Por que Playwright? (Recomendado sobre Puppeteer)
1. ‚úÖ **Suporta 3 navegadores** (Chromium, Firefox, WebKit)
2. ‚úÖ **API mais moderna** e f√°cil de usar
3. ‚úÖ **Auto-wait inteligente** (espera elementos automaticamente)
4. ‚úÖ **Mantido pelo Google** (mesma equipe do Puppeteer)
5. ‚úÖ **Melhor documenta√ß√£o**
6. ‚úÖ **Funciona no Deno** (nosso ambiente)

#### Passo 1: Instalar Playwright no Deno
```typescript
// supabase/functions/playwright-scraper/index.ts

// Importar Playwright para Deno
import { chromium } from 'https://deno.land/x/astral@0.4.1/mod.ts';
```

**IMPORTANTE:** Astral √© port do Playwright para Deno!

#### Passo 2: Criar Edge Function playwright-scraper
```typescript
// supabase/functions/playwright-scraper/index.ts

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import { chromium } from 'https://deno.land/x/astral@0.4.1/mod.ts';
import { corsHeaders } from '../_utils/cors.ts';

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  const { url, waitFor, selectors, screenshot = false } = await req.json();

  console.log('üé≠ Playwright: Launching browser...');

  let browser;
  try {
    // Lan√ßar navegador headless
    browser = await chromium.launch({
      headless: true,
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-gpu',
        '--no-first-run',
        '--no-zygote',
        '--single-process',
        '--ignore-certificate-errors', // ‚Üê IGNORA ERRO SSL!
        '--disable-blink-features=AutomationControlled', // ‚Üê ANTI-BOT
      ],
    });

    console.log('‚úÖ Browser launched');

    // Criar p√°gina
    const page = await browser.newPage({
      userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    });

    console.log('üìÑ Navigating to:', url);

    // Navegar para URL
    await page.goto(url, {
      waitUntil: 'networkidle', // Espera carregamento completo
      timeout: 30000,
    });

    // Esperar elemento espec√≠fico (se fornecido)
    if (waitFor) {
      console.log('‚è≥ Waiting for:', waitFor);
      await page.waitForSelector(waitFor, { timeout: 10000 });
    }

    // Rolar p√°gina para carregar lazy loading
    await page.evaluate(() => {
      window.scrollTo(0, document.body.scrollHeight);
    });
    await page.waitForTimeout(2000); // Esperar carregamento

    // Extrair dados
    console.log('üìä Extracting data...');
    
    let extractedData = {};
    
    if (selectors) {
      // Extrair usando seletores fornecidos
      for (const [key, selector] of Object.entries(selectors)) {
        const elements = await page.$$(selector as string);
        extractedData[key] = await Promise.all(
          elements.map(async (el) => {
            const text = await el.textContent();
            const href = await el.getAttribute('href');
            const src = await el.getAttribute('src');
            return { text: text?.trim(), href, src };
          })
        );
      }
    } else {
      // Extra√ß√£o autom√°tica de produtos
      extractedData = await page.evaluate(() => {
        // Padr√µes comuns de e-commerce
        const products: any[] = [];
        
        // Tentar m√∫ltiplos seletores
        const selectors = [
          '.product',
          '[data-product]',
          '.product-item',
          '.product-card',
          'article[itemtype*="Product"]',
        ];
        
        for (const selector of selectors) {
          const productElements = document.querySelectorAll(selector);
          
          if (productElements.length > 0) {
            productElements.forEach((el) => {
              const nameEl = el.querySelector('h2, h3, .product-title, .product-name, [itemprop="name"]');
              const priceEl = el.querySelector('.price, .product-price, [itemprop="price"]');
              const imgEl = el.querySelector('img');
              const linkEl = el.querySelector('a');
              
              if (nameEl || priceEl) {
                products.push({
                  name: nameEl?.textContent?.trim() || '',
                  price: priceEl?.textContent?.trim() || '',
                  image: imgEl?.src || '',
                  link: linkEl?.href || '',
                });
              }
            });
            
            if (products.length > 0) break;
          }
        }
        
        return { products, totalFound: products.length };
      });
    }

    // Screenshot (opcional)
    let screenshotBase64;
    if (screenshot) {
      console.log('üì∏ Taking screenshot...');
      const screenshotBuffer = await page.screenshot({ fullPage: false });
      screenshotBase64 = btoa(String.fromCharCode(...new Uint8Array(screenshotBuffer)));
    }

    await browser.close();
    console.log('‚úÖ Scraping completed');

    return new Response(
      JSON.stringify({
        success: true,
        url,
        data: extractedData,
        screenshot: screenshotBase64 ? `data:image/png;base64,${screenshotBase64}` : null,
        timestamp: new Date().toISOString(),
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );

  } catch (error: any) {
    console.error('‚ùå Playwright error:', error);
    
    if (browser) {
      await browser.close();
    }

    return new Response(
      JSON.stringify({
        success: false,
        error: error.message,
        stack: error.stack,
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});
```

#### Passo 3: Configurar permiss√µes Deno
```json
// supabase/functions/playwright-scraper/deno.json
{
  "permissions": {
    "net": true,
    "read": true,
    "write": true,
    "run": true,
    "env": true
  }
}
```

#### Passo 4: Deploy da fun√ß√£o
```bash
# Deploy
supabase functions deploy playwright-scraper

# Configurar secrets
supabase secrets set --env-file .env.local
```

#### Passo 5: Atualizar toolDefinitions.ts
```typescript
// src/lib/ai/tools/toolDefinitions.ts

// ATUALIZAR ferramenta web_scraping para usar Playwright:
{
  name: 'web_scraping',
  description: 'Faz web scraping REAL de p√°ginas usando navegador headless. Executa JavaScript, espera carregamento din√¢mico, funciona com SPAs (React/Vue/Angular). Use para raspar produtos, dados, extrair informa√ß√µes de qualquer site moderno.',
  parameters: {
    type: 'object',
    properties: {
      url: {
        type: 'string',
        description: 'URL da p√°gina a fazer scraping',
      },
      waitFor: {
        type: 'string',
        description: 'Seletor CSS para esperar antes de extrair (ex: ".product-list")',
      },
      selectors: {
        type: 'object',
        description: 'Seletores CSS para extrair dados espec√≠ficos (ex: {"title": "h1", "price": ".price"})',
      },
      screenshot: {
        type: 'boolean',
        description: 'Se true, retorna screenshot da p√°gina',
      },
    },
    required: ['url'],
  },
},

// ATUALIZAR scrape_products tamb√©m:
{
  name: 'scrape_products',
  description: 'Raspa dados de produtos de e-commerce usando navegador REAL. Funciona com Shopify, WooCommerce, VTEX, e qualquer loja moderna. Extrai nome, pre√ßo, imagens, descri√ß√£o automaticamente.',
  parameters: {
    type: 'object',
    properties: {
      url: {
        type: 'string',
        description: 'URL da p√°gina de produtos ou categoria',
      },
      maxProducts: {
        type: 'number',
        description: 'N√∫mero m√°ximo de produtos a extrair (padr√£o: 20)',
      },
      screenshot: {
        type: 'boolean',
        description: 'Se true, retorna screenshot da p√°gina',
      },
    },
    required: ['url'],
  },
},
```

#### Passo 6: Atualizar toolExecutor.ts
```typescript
// src/lib/ai/tools/toolExecutor.ts

// Atualizar mapeamento:
const TOOL_TO_FUNCTION_MAP: Record<string, string> = {
  // ...
  web_scraping: 'playwright-scraper',  // ‚Üê USAR PLAYWRIGHT!
  scrape_products: 'playwright-scraper', // ‚Üê USAR PLAYWRIGHT!
  // ...
};

// Atualizar executor:
async function executeWebScraping(args: any, accessToken: string): Promise<ToolResult> {
  const result = await callEdgeFunction('playwright-scraper', {
    url: args.url,
    waitFor: args.waitFor,
    selectors: args.selectors,
    screenshot: args.screenshot || false,
  }, accessToken);

  let message = `‚úÖ **Web scraping conclu√≠do:** ${args.url}\n\n`;
  
  if (result.data?.products) {
    const products = result.data.products.slice(0, 5);
    message += `üõçÔ∏è **${result.data.totalFound} produtos encontrados**\n\n`;
    message += products.map((p: any, i: number) => 
      `${i + 1}. **${p.name}**\n   üí∞ ${p.price}\n   üîó [Ver produto](${p.link})`
    ).join('\n\n');
  } else {
    message += `üìä **Dados extra√≠dos:**\n\n`;
    message += JSON.stringify(result.data, null, 2);
  }

  if (result.screenshot) {
    message += `\n\nüì∏ **Screenshot capturado**`;
  }

  return {
    success: true,
    data: result,
    message,
  };
}

async function executeScrapeProducts(args: any, accessToken: string, conversationId: string): Promise<ToolResult> {
  const result = await callEdgeFunction('playwright-scraper', {
    url: args.url,
    screenshot: args.screenshot || false,
  }, accessToken);

  const products = result.data?.products || [];
  const maxProducts = args.maxProducts || 20;
  const limitedProducts = products.slice(0, maxProducts);

  // Gerar CSV
  const csvContent = generateCSV(limitedProducts);

  // Upload para storage
  const fileName = `produtos_${Date.now()}.csv`;
  const uploadResult = await uploadToStorage(fileName, csvContent, accessToken);

  return {
    success: true,
    data: {
      totalProducts: products.length,
      extractedProducts: limitedProducts.length,
      products: limitedProducts,
      downloadUrl: uploadResult.signedUrl,
    },
    message: `‚úÖ **${products.length} produtos extra√≠dos** de ${args.url}\n\nüì• **[BAIXAR CSV](${uploadResult.signedUrl})**\n\nüõçÔ∏è **Preview:**\n${limitedProducts.slice(0, 3).map((p: any, i: number) => `${i + 1}. ${p.name} - ${p.price}`).join('\n')}`,
  };
}
```

---

## üìã PLANO DE A√á√ÉO COMPLETO

### üî¥ FASE 1: ARQUIVOS (1-2 horas)
- [ ] Criar bucket `temp-downloads` no Supabase
- [ ] Adicionar pol√≠ticas RLS para upload/download
- [ ] Corrigir `file-generator-v2` para retornar downloadUrl
- [ ] Testar cria√ß√£o de CSV
- [ ] Testar cria√ß√£o de JSON
- [ ] Testar cria√ß√£o de ZIP

### üü° FASE 2: BUSCA WEB (2-3 horas)
- [ ] Criar conta Brave Search API (gr√°tis)
- [ ] Implementar `web-search.ts` utility
- [ ] Criar Edge Function `web-search`
- [ ] Adicionar ferramenta `web_search` nas toolDefinitions
- [ ] Adicionar executor `executeWebSearch`
- [ ] Testar pesquisas na internet
- [ ] Configurar vari√°vel `BRAVE_SEARCH_API_KEY`

### üü¢ FASE 3: PLAYWRIGHT (4-6 horas) ‚ö†Ô∏è CR√çTICO
- [ ] Instalar Astral (Playwright para Deno)
- [ ] Criar Edge Function `playwright-scraper`
- [ ] Configurar permiss√µes Deno
- [ ] Testar scraping de site est√°tico
- [ ] Testar scraping de SPA (React/Vue)
- [ ] Testar bypass de anti-bot
- [ ] Testar extra√ß√£o de produtos
- [